{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\adminmkoohikamali\\.conda\\envs\\venvtext\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\adminmkoohikamali\\.conda\\envs\\venvtext\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\adminmkoohikamali\\.conda\\envs\\venvtext\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\adminmkoohikamali\\.conda\\envs\\venvtext\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\adminmkoohikamali\\.conda\\envs\\venvtext\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\adminmkoohikamali\\.conda\\envs\\venvtext\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#pip install nltk\n",
    "! pip install --user nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- -----------\n",
      "aiohttp                       3.8.4\n",
      "aiosignal                     1.3.1\n",
      "anyio                         3.6.2\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "asttokens                     2.2.1\n",
      "async-timeout                 4.0.2\n",
      "attrs                         22.2.0\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "beautifulsoup4                4.11.1\n",
      "bleach                        5.0.1\n",
      "brotlipy                      0.7.0\n",
      "certifi                       2022.12.7\n",
      "cffi                          1.15.1\n",
      "charset-normalizer            2.1.1\n",
      "click                         8.1.3\n",
      "colorama                      0.4.6\n",
      "comm                          0.1.2\n",
      "contourpy                     1.0.7\n",
      "cryptography                  39.0.0\n",
      "cycler                        0.11.0\n",
      "Cython                        0.29.34\n",
      "debugpy                       1.6.5\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "executing                     1.2.0\n",
      "fastjsonschema                2.16.2\n",
      "filelock                      3.9.0\n",
      "flit_core                     3.8.0\n",
      "fonttools                     4.39.3\n",
      "frozenlist                    1.3.3\n",
      "huggingface-hub               0.11.1\n",
      "idna                          3.4\n",
      "importlib-metadata            6.0.0\n",
      "importlib-resources           5.10.2\n",
      "ipykernel                     6.20.2\n",
      "ipython                       8.8.0\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    8.0.4\n",
      "jedi                          0.18.2\n",
      "Jinja2                        3.1.2\n",
      "joblib                        1.2.0\n",
      "jsonschema                    4.17.3\n",
      "jupyter                       1.0.0\n",
      "jupyter_client                7.4.9\n",
      "jupyter-console               6.4.4\n",
      "jupyter_core                  5.1.3\n",
      "jupyter-events                0.6.3\n",
      "jupyter_server                2.1.0\n",
      "jupyter_server_terminals      0.4.4\n",
      "jupyterlab-pygments           0.2.2\n",
      "jupyterlab-widgets            3.0.5\n",
      "keras                         2.11.0\n",
      "kiwisolver                    1.4.4\n",
      "MarkupSafe                    2.1.2\n",
      "matplotlib                    3.7.1\n",
      "matplotlib-inline             0.1.6\n",
      "mistune                       2.0.4\n",
      "multidict                     6.0.4\n",
      "nbclassic                     0.4.8\n",
      "nbclient                      0.7.2\n",
      "nbconvert                     7.2.8\n",
      "nbformat                      5.7.3\n",
      "nest-asyncio                  1.5.6\n",
      "networkx                      3.1\n",
      "nltk                          3.8.1\n",
      "notebook                      6.5.2\n",
      "notebook_shim                 0.2.2\n",
      "NRCLex                        3.0.0\n",
      "numpy                         1.24.1\n",
      "openai                        0.27.7\n",
      "openpyxl                      3.1.1\n",
      "packaging                     23.0\n",
      "pandas                        2.0.0\n",
      "pandocfilters                 1.5.0\n",
      "parso                         0.8.3\n",
      "patsy                         0.5.3\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.5.0\n",
      "pip                           23.1\n",
      "pkgutil_resolve_name          1.3.10\n",
      "platformdirs                  2.6.2\n",
      "plotly                        5.13.1\n",
      "ply                           3.11\n",
      "pmdarima                      2.0.3\n",
      "pooch                         1.6.0\n",
      "prometheus-client             0.15.0\n",
      "prompt-toolkit                3.0.36\n",
      "psutil                        5.9.4\n",
      "pure-eval                     0.2.2\n",
      "pycparser                     2.21\n",
      "Pygments                      2.14.0\n",
      "pyOpenSSL                     23.0.0\n",
      "pyparsing                     3.0.9\n",
      "PyQt5                         5.15.7\n",
      "PyQt5-sip                     12.11.0\n",
      "pyrsistent                    0.19.3\n",
      "PySocks                       1.7.1\n",
      "python-dateutil               2.8.2\n",
      "python-json-logger            2.0.4\n",
      "pytz                          2023.3\n",
      "pywin32                       304\n",
      "pywinpty                      2.0.10\n",
      "PyYAML                        6.0\n",
      "pyzmq                         25.0.0\n",
      "qtconsole                     5.4.0\n",
      "QtPy                          2.3.0\n",
      "regex                         2022.10.31\n",
      "requests                      2.28.2\n",
      "rfc3339-validator             0.1.4\n",
      "rfc3986-validator             0.1.1\n",
      "scikit-learn                  1.2.1\n",
      "scipy                         1.10.0\n",
      "Send2Trash                    1.8.0\n",
      "sentencepiece                 0.1.97\n",
      "setuptools                    66.1.1\n",
      "sip                           6.7.5\n",
      "six                           1.16.0\n",
      "sniffio                       1.3.0\n",
      "soupsieve                     2.3.2.post1\n",
      "stack-data                    0.6.2\n",
      "statsmodels                   0.13.5\n",
      "tenacity                      8.2.2\n",
      "terminado                     0.17.0\n",
      "textblob                      0.17.1\n",
      "threadpoolctl                 3.1.0\n",
      "tinycss2                      1.2.1\n",
      "tokenizers                    0.13.2\n",
      "toml                          0.10.2\n",
      "tornado                       6.2\n",
      "tqdm                          4.64.1\n",
      "traitlets                     5.8.1\n",
      "transformers                  4.25.1\n",
      "typing_extensions             4.4.0\n",
      "tzdata                        2023.3\n",
      "urllib3                       1.26.14\n",
      "wcwidth                       0.2.6\n",
      "webencodings                  0.5.1\n",
      "websocket-client              1.4.2\n",
      "wheel                         0.38.4\n",
      "widgetsnbextension            4.0.5\n",
      "win-inet-pton                 1.1.0\n",
      "wordcloud                     1.9.2\n",
      "yarl                          1.9.2\n",
      "zipp                          3.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to C:\\Users\\adminmkoohikamali\n",
      "[nltk_data]    |     \\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to C:\\Users\\adminmkoohikam\n",
      "[nltk_data]    |     ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to C:\\\n",
      "[nltk_data]    |     Users\\adminmkoohikamali\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to \n",
      "[nltk_data]    |     C:\\Users\\adminmkoohikamali\\AppData\\Roaming\\nltk_d\n",
      "[nltk_data]    |     ata...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to C:\\Users\\admin\n",
      "[nltk_data]    |     mkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to C:\\Users\\adminmkoohikama\n",
      "[nltk_data]    |     li\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to C:\\Users\\admin\n",
      "[nltk_data]    |     mkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to C:\\Users\\admi\n",
      "[nltk_data]    |     nmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to C:\\Users\\adminmk\n",
      "[nltk_data]    |     oohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to C:\\Users\\adminmkoohikama\n",
      "[nltk_data]    |     li\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to C:\\Users\\adminmkoohikam\n",
      "[nltk_data]    |     ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to C:\\Users\\adminmk\n",
      "[nltk_data]    |     oohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to C:\\Users\n",
      "[nltk_data]    |     \\adminmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to C:\\Users\\a\n",
      "[nltk_data]    |     dminmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to C:\\Users\\adminmkoohikama\n",
      "[nltk_data]    |     li\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to C:\\Users\\adminmko\n",
      "[nltk_data]    |     ohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to C:\\Users\\adminmko\n",
      "[nltk_data]    |     ohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to C:\\Users\\adminmko\n",
      "[nltk_data]    |     ohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to C:\\Users\\adminmko\n",
      "[nltk_data]    |     ohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to C:\\Users\\adminmkooh\n",
      "[nltk_data]    |     ikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to C:\\Users\\adminmkoohikamal\n",
      "[nltk_data]    |     i\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to C:\\Users\\adminmkoohikam\n",
      "[nltk_data]    |     ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to C:\\Users\\adminmkoohikama\n",
      "[nltk_data]    |     li\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to C:\\Users\\adminmkoohikama\n",
      "[nltk_data]    |     li\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to C:\\Users\\adminmkoohikamal\n",
      "[nltk_data]    |     i\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to C:\\Users\\adminm\n",
      "[nltk_data]    |     koohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to C:\\Users\\adminmk\n",
      "[nltk_data]    |     oohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to C:\\Users\\adminmkooh\n",
      "[nltk_data]    |     ikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to C:\\Users\\adminmkoo\n",
      "[nltk_data]    |     hikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to C:\\Users\\adm\n",
      "[nltk_data]    |     inmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to C:\\\n",
      "[nltk_data]    |     Users\\adminmkoohikamali\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to C:\\Users\\adminmko\n",
      "[nltk_data]    |     ohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to C:\\Users\\adminmk\n",
      "[nltk_data]    |     oohikamali\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to C:\\Users\\adminmkoohikama\n",
      "[nltk_data]    |     li\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to C:\\Users\\adminmkoo\n",
      "[nltk_data]    |     hikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to C:\\Users\\\n",
      "[nltk_data]    |     adminmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to C:\\Users\\adminmkoohikamali\n",
      "[nltk_data]    |     \\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to C:\\Users\\admin\n",
      "[nltk_data]    |     mkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to C:\\Users\\adminm\n",
      "[nltk_data]    |     koohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to C:\\Users\\adminmkoohikamal\n",
      "[nltk_data]    |     i\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to C:\\Users\\adminmko\n",
      "[nltk_data]    |     ohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to C:\\Users\\adminmkoohikamali\n",
      "[nltk_data]    |     \\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to C:\\Users\\adminmkoohikam\n",
      "[nltk_data]    |     ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to C:\\Users\\adminmkoo\n",
      "[nltk_data]    |     hikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to C:\\Users\\admin\n",
      "[nltk_data]    |     mkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to C:\\Users\\adm\n",
      "[nltk_data]    |     inmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to C:\\Users\\adm\n",
      "[nltk_data]    |     inmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to C:\\Users\\adminmkoohikamali\n",
      "[nltk_data]    |     \\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to C:\\Users\\adminmkoohikama\n",
      "[nltk_data]    |     li\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to C:\\Users\\adminmkoohikamali\\\n",
      "[nltk_data]    |     AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to C:\\Users\\adminmkoohikamal\n",
      "[nltk_data]    |     i\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to C:\\Users\\adminmkoohikamali\n",
      "[nltk_data]    |     \\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to C:\\Users\\admin\n",
      "[nltk_data]    |     mkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to C:\\Users\\adminmkoohikam\n",
      "[nltk_data]    |     ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to C:\\Users\\adm\n",
      "[nltk_data]    |     inmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to C:\\Users\\adminmko\n",
      "[nltk_data]    |     ohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to C:\\Users\\adminmkoo\n",
      "[nltk_data]    |     hikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to C:\\Users\\admin\n",
      "[nltk_data]    |     mkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to C:\\Users\\adminmk\n",
      "[nltk_data]    |     oohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to C:\\Users\\admi\n",
      "[nltk_data]    |     nmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to C:\\Users\\adminmkoo\n",
      "[nltk_data]    |     hikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to C:\\Users\\adminmko\n",
      "[nltk_data]    |     ohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to C:\\Users\\adminmkoo\n",
      "[nltk_data]    |     hikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to C:\\Users\\adminmkoohikama\n",
      "[nltk_data]    |     li\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to C:\\Users\\admin\n",
      "[nltk_data]    |     mkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to C:\\Users\\adminmkoohikamal\n",
      "[nltk_data]    |     i\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to C:\\Users\\adminmkoohikama\n",
      "[nltk_data]    |     li\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to C:\\Users\\admin\n",
      "[nltk_data]    |     mkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to C:\\Users\\admi\n",
      "[nltk_data]    |     nmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to C:\\Use\n",
      "[nltk_data]    |     rs\\adminmkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to C:\\Users\\adminmk\n",
      "[nltk_data]    |     oohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to C:\\Users\\adminmkoohik\n",
      "[nltk_data]    |     amali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to C:\\Users\\adminmkooh\n",
      "[nltk_data]    |     ikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to C:\\Users\\admin\n",
      "[nltk_data]    |     mkoohikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to C:\\Users\\adminmkoohika\n",
      "[nltk_data]    |     mali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to C:\\Users\\adminmkoo\n",
      "[nltk_data]    |     hikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to C:\\Users\\adminmkoo\n",
      "[nltk_data]    |     hikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to C:\\Users\\adminmkoohi\n",
      "[nltk_data]    |     kamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to C:\\Users\\adminmkooh\n",
      "[nltk_data]    |     ikamali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to C:\\Users\\adminmkoohikama\n",
      "[nltk_data]    |     li\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to C:\\Users\\adminmkoohikamal\n",
      "[nltk_data]    |     i\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download()\n",
    "nltk.download('all', halt_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the brown corpus - The first million-word corpus for the English Language\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total categories: 15\n"
     ]
    }
   ],
   "source": [
    "#total categories\n",
    "print ('total categories:', len(brown.categories()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "#print the categoires\n",
    "print (brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['They', 'neither', 'liked', 'nor', 'disliked', 'the', 'Old', 'Man', '.'], ['To', 'them', 'he', 'could', 'have', 'been', 'the', 'broken', 'bell', 'in', 'the', 'church', 'tower', 'which', 'rang', 'before', 'and', 'after', 'Mass', ',', 'and', 'at', 'noon', ',', 'and', 'at', 'six', 'each', 'evening', '--', 'its', 'tone', ',', 'repetitive', ',', 'monotonous', ',', 'never', 'breaking', 'the', 'boredom', 'of', 'the', 'streets', '.'], ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenized sentences\n",
    "brown.sents(categories='romance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('They', 'PPSS'), ('neither', 'CC'), ('liked', 'VBD'), ('nor', 'CC'), ('disliked', 'VBD'), ('the', 'AT'), ('Old', 'JJ-TL'), ('Man', 'NN-TL'), ('.', '.')], [('To', 'IN'), ('them', 'PPO'), ('he', 'PPS'), ('could', 'MD'), ('have', 'HV'), ('been', 'BEN'), ('the', 'AT'), ('broken', 'VBN'), ('bell', 'NN'), ('in', 'IN'), ('the', 'AT'), ('church', 'NN'), ('tower', 'NN'), ('which', 'WDT'), ('rang', 'VBD'), ('before', 'IN'), ('and', 'CC'), ('after', 'IN'), ('Mass', 'NN-TL'), (',', ','), ('and', 'CC'), ('at', 'IN'), ('noon', 'NN'), (',', ','), ('and', 'CC'), ('at', 'IN'), ('six', 'CD'), ('each', 'DT'), ('evening', 'NN'), ('--', '--'), ('its', 'PP$'), ('tone', 'NN'), (',', ','), ('repetitive', 'JJ'), (',', ','), ('monotonous', 'JJ'), (',', ','), ('never', 'RB'), ('breaking', 'VBG'), ('the', 'AT'), ('boredom', 'NN'), ('of', 'IN'), ('the', 'AT'), ('streets', 'NNS'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#POS tagged sentences\n",
    "brown.tagged_sents(categories='romance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There were thirty-eight patients on the bus the morning I left for Hanover , most of them disturbed and hallucinating .',\n",
       " 'An interne , a nurse and two attendants were in charge of us .',\n",
       " \"I felt lonely and depressed as I stared out the bus window at Chicago's grim , dirty West Side .\",\n",
       " 'It seemed incredible , as I listened to the monotonous drone of voices and smelled the fetid odors coming from the patients , that technically I was a ward of the state of Illinois , going to a hospital for the mentally ill .',\n",
       " 'I suddenly thought of Mary Jane Brennan , the way her pretty eyes could flash with anger , her quiet competence , the gentleness and sweetness that lay just beneath the surface of her defenses .']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get sentences in natural form\n",
    "sentences = brown.sents(categories='mystery')\n",
    "sentences = [' '.join(setnece_token) for setnece_token in sentences]\n",
    "sentences[0:5] #view the first 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access WordNet Corpus - A Semantic oriented lexical database for English Language, created by Princeton University\n",
    "#Constsis of words and synomys (Synsets), definitions, relationships and examples.\n",
    "#Combination of a dictionary as well as a Thesaurus\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'credit' #taking hike as a sample word of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('recognition.n.03'),\n",
       " Synset('credit.n.02'),\n",
       " Synset('credit.n.03'),\n",
       " Synset('credit.n.04'),\n",
       " Synset('credit.n.05'),\n",
       " Synset('credit.n.06'),\n",
       " Synset('citation.n.03'),\n",
       " Synset('credit.n.08'),\n",
       " Synset('credit_rating.n.01'),\n",
       " Synset('credit.v.01'),\n",
       " Synset('accredit.v.03'),\n",
       " Synset('credit.v.03'),\n",
       " Synset('credit.v.04')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get word synsets\n",
    "word_synsets = wn.synsets(word)\n",
    "word_synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset name:recognition.n.03\n",
      "POS Tag:n\n",
      "Definition:approval\n",
      "Examples:['give her recognition for trying', 'he was given credit for his work', 'give her credit for trying']\n",
      "\n",
      "Synset name:credit.n.02\n",
      "POS Tag:n\n",
      "Definition:money available for a client to borrow\n",
      "Examples:[]\n",
      "\n",
      "Synset name:credit.n.03\n",
      "POS Tag:n\n",
      "Definition:an accounting entry acknowledging income or capital items\n",
      "Examples:[]\n",
      "\n",
      "Synset name:credit.n.04\n",
      "POS Tag:n\n",
      "Definition:used in the phrase `to your credit' in order to indicate an achievement deserving praise\n",
      "Examples:['she already had several performances to her credit']\n",
      "\n",
      "Synset name:credit.n.05\n",
      "POS Tag:n\n",
      "Definition:arrangement for deferred payment for goods and services\n",
      "Examples:[]\n",
      "\n",
      "Synset name:credit.n.06\n",
      "POS Tag:n\n",
      "Definition:recognition by a college or university that a course of studies has been successfully completed; typically measured in semester hours\n",
      "Examples:[]\n",
      "\n",
      "Synset name:citation.n.03\n",
      "POS Tag:n\n",
      "Definition:a short note recognizing a source of information or of a quoted passage\n",
      "Examples:[\"the student's essay failed to list several important citations\", 'the acknowledgments are usually printed at the front of a book', 'the article includes mention of similar clinical cases']\n",
      "\n",
      "Synset name:credit.n.08\n",
      "POS Tag:n\n",
      "Definition:an entry on a list of persons who contributed to a film or written work\n",
      "Examples:['the credits were given at the end of the film']\n",
      "\n",
      "Synset name:credit_rating.n.01\n",
      "POS Tag:n\n",
      "Definition:an estimate, based on previous dealings, of a person's or an organization's ability to fulfill their financial commitments\n",
      "Examples:[]\n",
      "\n",
      "Synset name:credit.v.01\n",
      "POS Tag:v\n",
      "Definition:give someone credit for something\n",
      "Examples:['We credited her for saving our jobs']\n",
      "\n",
      "Synset name:accredit.v.03\n",
      "POS Tag:v\n",
      "Definition:ascribe an achievement to\n",
      "Examples:['She was not properly credited in the program']\n",
      "\n",
      "Synset name:credit.v.03\n",
      "POS Tag:v\n",
      "Definition:accounting: enter as credit\n",
      "Examples:['We credit your account with $100']\n",
      "\n",
      "Synset name:credit.v.04\n",
      "POS Tag:v\n",
      "Definition:have trust in; trust in the truth or veracity of\n",
      "Examples:[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get details of each synonym in synset\n",
    "for synset in word_synsets:\n",
    "    print (('Synset name:{name}\\n'\n",
    "           'POS Tag:{tag}\\n'\n",
    "           'Definition:{defn}\\n'\n",
    "           'Examples:{ex}\\n').format(name=synset.name(),\n",
    "                                    tag=synset.pos(),\n",
    "                                    defn=synset.definition(),\n",
    "                                    ex=synset.examples()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
